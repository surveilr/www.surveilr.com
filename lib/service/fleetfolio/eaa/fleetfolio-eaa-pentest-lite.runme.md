---
runme:
  id: fleetfolio-eaa-pentest-lite
  name: "Fleetfolio EAA – Pentest Lite (Authorized)"
  version: "2.0.0"
  maintainer: "Fleetfolio Team"
  description: "Lightweight, authorized, container-run external asset assessment with structured artifacts."
---

This Runme runbook performs an **authorized, lightweight external asset assessment** inside an OWASP Nightingale container
(default base: `rajanagori/nightingale:latest`). It orchestrates a chain of reconnaissance and validation tools to
discover domains, resolve DNS, probe for web services, scan ports, fingerprint technologies, check TLS certificates, and run
targeted vulnerability checks. All artifacts are stored under `/var/fleetfolio/eaa/<tool>/…` in structured formats such as
JSON, JSONL, XML, or plain text.

The runbook is meant to be **safe, idempotent, and scope-aware**, honoring exclusions and customer authorization.

All the packages come from `Debian`. When they don’t come from Debian, we use `Homebrew`. If not available in Homebrew, we use `eget`. If none of these work, we install it directly using the runtime installation instructions.

## Roadmap

- [ ] Introduce [Rustscan](https://github.com/bee-san/RustScan) for Ultra-fast port scanner with intelligent rate limiting
- [ ] Introduce [Masscan](https://www.kali.org/tools/masscan/) for High-speed Internet-scale port scanning with banner grabbing
- [ ] Introduce [AutoRecon](https://github.com/Tib3rius/AutoRecon) for Comprehensive automated reconnaissance with 35+ parameters
- [ ] Introduce [Amass](https://github.com/owasp-amass/amass) for Advanced subdomain enumeration and OSINT gathering
- [ ] Introduce [Fierce](https://github.com/mschwager/fierce) for DNS reconnaissance and zone transfer testing
- [ ] Introduce [DNSEnum](https://www.kali.org/tools/dnsenum/) for DNS information gathering and subdomain brute forcing
- [ ] Introduce [TheHarvester](https://github.com/laramies/theHarvester) for Email and subdomain harvesting from multiple sources

## Manual Installation of Kali Linux in VirtualBox

This guide will help you manually install **Kali Linux** in **VirtualBox** on your host machine.

### Prerequisites

- **VirtualBox**: [Download VirtualBox](https://www.virtualbox.org/wiki/Downloads)
- If you are using Windows as the host machine, you may encounter an error while downloading or installing VirtualBox due to missing Visual C++ dependencies. To resolve this, download the package from [Visual C++ Redistributable Runtimes All-in-One](https://www.techpowerup.com/download/visual-c-redistributable-runtime-package-all-in-one)
and run the `install_all.bat` file.
- **Kali Linux Virtual Machine**: [Download Kali Linux VM](https://www.kali.org/get-kali/#kali-platforms) (VirtualBox, 3.3 GB, `.7z` file)
- **WinRAR** or **7-Zip** for extraction: [Download WinRAR](https://www.win-rar.com/download.html?&L=0) (recommended)

#### Steps

1. **Download Kali Linux**

   - Select **Virtual Machine** and then **VirtualBox (3.3 GB)**.
   - The file will be in `.7z` format.

2. **Download and install VirtualBox**

   - Open [VirtualBox Downloads](https://www.virtualbox.org/wiki/Downloads) and install it on your host machine.

3. **Extract Kali Linux VM**

   - Use **WinRAR** or **7-Zip** to extract the `.7z` file to your **Downloads** folder.
   - There will be two files: A `.vdi` file (orange icon) and one `.vbox file` (blue icon). Double-click on the `.vbox` file to automatically import the Kali Linux Machine into VirtualBox.

4. **Configure the Virtual Machine**

   - Set **Base Memory** to `4096 MB` (recommended).
   - Set **Processor Cores** to `2–3` (recommended).
   - Start the virtual machine.

5. **Login**

- Default credentials:

```text { ignore=true }
Username: kali
Password: kali
```

6. **Switch to Root User**

- Open the terminal and type:

```bash { ignore=true }
sudo su
```

- This will give you root privileges (most privileged user).

7. **Update the System**

- In the terminal, run:

```bash { ignore=true }
sudo apt update && sudo apt upgrade -y && sudo apt full-upgrade -y
```

- This will ensure your system is fully updated and prevent errors when installing tools.

**Note:** Always use updated VirtualBox and Kali Linux versions to avoid compatibility issues.

## Fixing Errors

If you encounter any errors while running the above system update commands, follow these steps:

```bash { ignore=true }
sudo sed -i 's|http://http.kali.org|https://http.kali.org|' /etc/apt/sources.list
```

Then run the following commands one by one:

```bash { ignore=true }
sudo apt-get clean && sudo apt-get update --fix-missing
```

Then run the system update command again:

```bash { ignore=true }
sudo apt update && sudo apt upgrade -y && sudo apt full-upgrade -y
```

---

### Prerequisite Dependency

**Homebrew**

```bash { ignore=true }
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)" && echo >> /home/kali/.zshrc && echo 'eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"' >> /home/kali/.zshrc && eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)" && sudo apt-get install -y build-essential && brew install gcc
```

Note : Run this command inside a non-root user terminal. You will be prompted to enter the password, and then press Enter again to continue

**Go**

```bash { ignore=true }
sudo apt install golang-go -y
```

---

#### Install [RUNME](https://github.com/runmedev/runme)

To get started with Runme on Linux, the recommended method of installation is using Homebrew, a popular package manager that simplifies the installation process. First, ensure your Homebrew is up to date to avoid any compatibility issues:

```bash { ignore=true }
brew update && brew install runme
```

#### Install [Varlock](https://github.com/dmno-dev/varlock)

Varlock is a tool for managing and validating environment variables using a schema file, ensuring all required variables are correctly set before running commands. It adds consistency, security, and reliability to workflows that depend on .env files.
To install:

```bash { ignore=true }
brew install dmno-dev/tap/varlock
```

Homebrew-installed tools not accessible when switching to root user (Solution: Add Homebrew to root’s shell environment)

```bash { ignore=true }
sudo su && echo 'eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"' >> /root/.zshrc && eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"
```

#### Install [Surveilr](https://github.com/opsfolio/releases.opsfolio.com/releases)

Get the latest Resource Surveillance & Integration Engine (surveilr) for Critical Systems by following these steps to complete the installation:

```bash { ignore=true }
sudo apt install wget &&  wget https://github.com/opsfolio/releases.opsfolio.com/releases/download/2.2.0/resource-surveillance_2.2.0_x86_64-unknown-linux-gnu.tar.gz && \
tar -xvf resource-surveillance_2.2.0_x86_64-unknown-linux-gnu.tar.gz && \
mv surveilr /usr/local/bin
```

## Tools Required and Their Installation Steps

#### Whatweb, Nmap, Openssl, wafw00f, sqlmap are Pre-installed in kali linux

```bash { ignore=true }
sudo apt install -y subfinder dnsx httpx-toolkit naabu nuclei xq jq dirsearch testssl.sh && \
go install github.com/projectdiscovery/katana/cmd/katana@latest && sudo cp ~/go/bin/katana /bin/  && \
go install github.com/projectdiscovery/tlsx/cmd/tlsx@latest && sudo cp ~/go/bin/tlsx /bin/
go install -v github.com/PentestPad/subzy@latest && sudo cp ~/go/bin/subzy /bin/
```
## Then Clone this repo

```bash { ignore=true }
git clone https://github.com/surveilr/www.surveilr.com.git && \
cd www.surveilr.com/lib/service/fleetfolio/eaa
```

- Then add the domains, URLs, IPs, etc. inside the .env file.
   Example

```bash { ignore=true }
sudo tee -a .env > /dev/null << 'EOF'

# Copy this file to ".env" and adjust values as needed.
# docker-compose will automatically read .env in the same folder.

# Scope configuration (space- or comma-separated)
OPSFOLIO_EAA_HOME=/opt/eaa/sessions
OPSFOLIO_EAA_TENANT_ID=NET1234
OPSFOLIO_EAA_TENANT_NAME=Netspective
OPSFOLIO_EAA_PURPOSE=Threat
OPSFOLIO_EAA_DESCRIPTION=Demo_Threat
OPSFOLIO_EAA_CONTEXT_JSON='{ "Sample": "Value" }'
OPSFOLIO_EAA_DOMAINS=netspective.com
OPSFOLIO_EAA_SUBDOMAINS=
OPSFOLIO_EAA_IP_RANGES=
OPSFOLIO_EAA_EXCLUDES=
OPSFOLIO_EAA_KEY_URLS=https://netspective.com
OPSFOLIO_EAA_RATE_LIMIT=200
OPSFOLIO_EAA_CONCURRENCY=50
OPSFOLIO_EAA_NAABU_PORTS=top-100
OPSFOLIO_EAA_NUCLEI_TEMPLATES=cves,default
EOF
```

- Then follow these steps

## Run Varlock with Runme to Execute Fleetfolio Pentest Workflow

```bash { ignore=true }
varlock init && varlock load && varlock run -- runme run --filename="fleetfolio-eaa-pentest-lite.runme.md" --all
```

Note: Make sure you are the root user and inside the eaa directory before running the above command. Then, press "y" twice to ensure that the environment variables are declared by Varlock

---

## Automated Method (Docker)

- First download docker

```bash { ignore=true }
sudo apt update && sudo apt install docker.io -y && sudo systemctl enable docker --now
```

If you encounter any errors while running the above system update commands, follow these steps:

```bash { ignore=true }
sudo sed -i 's|http://http.kali.org|https://http.kali.org|' /etc/apt/sources.list && sudo apt-get clean && sudo apt-get update --fix-missing
```

- Then Clone this repo

```bash { ignore=true }
git clone https://github.com/surveilr/www.surveilr.com.git && \
cd www.surveilr.com/lib/service/fleetfolio/eaa
```

- Then add the domains, URLs, IPs, etc. inside the .env file.
   Example

```bash { ignore=true }
sudo tee -a .env > /dev/null << 'EOF'

# Copy this file to ".env" and adjust values as needed.
# docker-compose will automatically read .env in the same folder.

# Scope configuration (space- or comma-separated)
OPSFOLIO_EAA_HOME=/opt/eaa/sessions
OPSFOLIO_EAA_TENANT_ID=NET1234
OPSFOLIO_EAA_TENANT_NAME=Netspective
OPSFOLIO_EAA_PURPOSE=Threat
OPSFOLIO_EAA_DESCRIPTION=Demo_Threat
OPSFOLIO_EAA_CONTEXT_JSON='{ "Sample": "Value" }'
OPSFOLIO_EAA_DOMAINS=netspective.com
OPSFOLIO_EAA_SUBDOMAINS=
OPSFOLIO_EAA_IP_RANGES=
OPSFOLIO_EAA_EXCLUDES=
OPSFOLIO_EAA_KEY_URLS=https://netspective.com
OPSFOLIO_EAA_RATE_LIMIT=200
OPSFOLIO_EAA_CONCURRENCY=50
OPSFOLIO_EAA_NAABU_PORTS=top-100
OPSFOLIO_EAA_NUCLEI_TEMPLATES=cves,default
EOF
```
- Then follow these steps

```bash { ignore=true }
sudo docker build -t fleetfolio-eaa:latest . && \
sudo docker run --rm -it -v $(pwd)/results:/opt/eaa/sessions/ fleetfolio-eaa:latest
```

Note: After running the `docker run` command, a new directory called `results` will be created in the current path on your local machine. This directory will contain the generated results from the Docker container, based on the scope you provided.

## Environment Variables

- `OPSFOLIO_EAA_HOME` – (default: `.fleetfolio/eaa` in current directory)
- `OPSFOLIO_EAA_TENANT_ID` – tenant IDs, separated by commas or spaces
- `OPSFOLIO_EAA_TENANT_NAME` – tenant names, separated by commas or spaces
- `OPSFOLIO_EAA_PURPOSE`   –    required string
- `OPSFOLIO_EAA_DESCRIPTION` –   optional string
- `OPSFOLIO_EAA_CONTEXT_JSON`   –     optional JSON object
- `OPSFOLIO_EAA_DOMAINS` – comma- or space-separated domains
- `OPSFOLIO_EAA_IP_RANGES` – comma- or space-separated IPs/CIDRs
- `OPSFOLIO_EAA_KEY_URLS` – comma- or space-separated URLs/APIs
- `OPSFOLIO_EAA_EXCLUDES` – comma- or space-separated exclusions
- `OPSFOLIO_EAA_RATE_LIMIT` – (default: 200)
- `OPSFOLIO_EAA_CONCURRENCY` – (default: 50)
- `OPSFOLIO_EAA_NAABU_PORTS` – (default: top-100)
- `OPSFOLIO_EAA_NUCLEI_TEMPLATES` – (default: cves,default)

# Initialization and Logging

The runbook begins by creating a working directory for session data, evidence, and logs. It snapshots all Fleetfolio-related
environment variables so that the test configuration is preserved for auditability. The master log file is written to
`$OPSFOLIO_EAA_HOME/runbook.log`.

```bash { name=init }
# Generate timestamp for the session folder
timestamp=$(date +'%Y-%m-%d-%H-%M-%S')

# Define dynamic output directory
export OPSFOLIO_EAA_HOME="/opt/eaa/sessions/$timestamp"
export OPSFOLIO_EAA_SESSION_HOME="$OPSFOLIO_EAA_HOME/.session"

# Create the necessary directories
mkdir -p "$OPSFOLIO_EAA_SESSION_HOME"

# Initialize log and arguments file inside the timestamped session directory
LOG="$OPSFOLIO_EAA_SESSION_HOME/runbook.log"
(env | grep ^OPSFOLIO_EAA_ || true) > "$OPSFOLIO_EAA_SESSION_HOME/arguments.env"
echo "[init] Snapshot written to $OPSFOLIO_EAA_SESSION_HOME/arguments.env" | tee -a "$LOG"

```

Artifacts: `$OPSFOLIO_EAA_HOME/arguments.env` (environment variables in `key=value` format) and the master runbook log
at `$OPSFOLIO_EAA_HOME/runbook.log`.

# Scope Normalization

Environment variables are convenient but not ideal for tool chaining. Here we normalize them into newline-delimited files so
each tool can consume scope easily.

```bash { name=normalize_scope }
# Ensure .env is loaded from the correct location
if [ -f .env ]; then
  echo "[INFO] .env file found in current dir, loading..."
  set -a
  . ./.env
  set +a
elif [ -f /opt/eaa/.env ]; then
  echo "[INFO] .env file found in /opt/eaa/, loading..."
  set -a
  . /opt/eaa/.env
  set +a
else
  echo "[ERROR] .env file not found!"
  exit 1
fi

# Reuse the timestamp from the environment snapshot created earlier
if [ -z "${timestamp:-}" ] && [ -f "$OPSFOLIO_EAA_SESSION_HOME/arguments.env" ]; then
  # Load environment from first snippet
  set -a
  . "$OPSFOLIO_EAA_SESSION_HOME/arguments.env"
  set +a
fi

# Ensure OPSFOLIO_EAA_HOME is set correctly
: "${OPSFOLIO_EAA_HOME:?OPSFOLIO_EAA_HOME must be set in .env}"
export OPSFOLIO_EAA_SESSION_HOME="$OPSFOLIO_EAA_HOME/.session"

# Create the session folder in the timestamped directory
mkdir -p "$OPSFOLIO_EAA_SESSION_HOME"

# Copy runbook to the session folder
env > "$OPSFOLIO_EAA_SESSION_HOME/.env"
cp fleetfolio-eaa-pentest-lite.runme.md $OPSFOLIO_EAA_SESSION_HOME

# Normalize scope variables into text files inside the .session folder
echo "${OPSFOLIO_EAA_TENANT_ID:-}"   | tr ', ' '\n' | sed '/^$/d' > "$OPSFOLIO_EAA_SESSION_HOME/tenant_id.txt"
echo "${OPSFOLIO_EAA_TENANT_NAME:-}" | tr ', ' '\n' | sed '/^$/d' > "$OPSFOLIO_EAA_SESSION_HOME/tenant_name.txt"
echo "${OPSFOLIO_EAA_PURPOSE:-}"   | tr ', ' '\n' | sed '/^$/d' > "$OPSFOLIO_EAA_SESSION_HOME/purpose.txt"
echo "${OPSFOLIO_EAA_DESCRIPTION:-}" | tr ', ' '\n' | sed '/^$/d' > "$OPSFOLIO_EAA_SESSION_HOME/description.txt"
echo "${OPSFOLIO_EAA_CONTEXT_JSON:-}"   | tr ', ' '\n' | sed '/^$/d' > "$OPSFOLIO_EAA_SESSION_HOME/context.json"
echo "${OPSFOLIO_EAA_DOMAINS:-}"   | tr ', ' '\n' | sed '/^$/d' > "$OPSFOLIO_EAA_SESSION_HOME/domains.txt"
echo "${OPSFOLIO_EAA_SUBDOMAINS:-}"| tr ', ' '\n' | sed '/^$/d' > "$OPSFOLIO_EAA_SESSION_HOME/subdomains.txt"
echo "${OPSFOLIO_EAA_IP_RANGES:-}" | tr ', ' '\n' | sed '/^$/d' > "$OPSFOLIO_EAA_SESSION_HOME/ip_ranges.txt"
echo "${OPSFOLIO_EAA_KEY_URLS:-}"  | tr ', ' '\n' | sed '/^$/d' > "$OPSFOLIO_EAA_SESSION_HOME/key_urls.txt"
echo "${OPSFOLIO_EAA_EXCLUDES:-}"  | tr ', ' '\n' | sed '/^$/d' > "$OPSFOLIO_EAA_SESSION_HOME/excludes.txt"
```

Artifacts: text files under `$OPSFOLIO_EAA_HOME/.session/` for domains, IP ranges, key URLs, and excludes.

# Subfinder – Discovering Subdomains

[Subfinder](https://github.com/projectdiscovery/subfinder) A subdomain discovery tool that uses passive online sources to quickly enumerate subdomains for a given domain. It’s widely used in reconnaissance to map the attack surface.  
**Use Cases:**

- Discovering subdomains of a target organization during reconnaissance.
- Expanding attack surface before vulnerability scanning.
- Validating scope in bug bounty programs.

```bash { name=subfinder }

# Define output path for subfinder
OUT="$OPSFOLIO_EAA_HOME/subfinder/subfinder.jsonl"
mkdir -p "$(dirname "$OUT")"

DOMAINS_FILE="$OPSFOLIO_EAA_SESSION_HOME/domains.txt"
SUBDOMAINS_FILE="$OPSFOLIO_EAA_SESSION_HOME/subdomains.txt"

# Prepare input files if they exist in .env
if [ -n "${OPSFOLIO_EAA_DOMAINS:-}" ]; then
  echo "$OPSFOLIO_EAA_DOMAINS" | tr ' ,;' '\n' > "$DOMAINS_FILE"
fi

if [ -n "${OPSFOLIO_EAA_SUBDOMAINS:-}" ]; then
  echo "$OPSFOLIO_EAA_SUBDOMAINS" | tr ' ,;' '\n' > "$SUBDOMAINS_FILE"
fi

# Case 1: Domains present → run subfinder as usual
if [ -s "$DOMAINS_FILE" ]; then
  while read -r DOMAIN; do
    BASE=$(echo "$DOMAIN" | awk -F. '{print $(NF-1)"."$NF}')
    if [ "$DOMAIN" = "$BASE" ]; then
      subfinder -d "$DOMAIN" -oJ -silent >> "$OUT" || true
    else
      echo "$DOMAIN" | dnsx -resp -silent | jq -R '{host:.}' >> "$OUT" || true
    fi
  done < "$DOMAINS_FILE"

# Case 2: No domains, but subdomains provided → just save them
elif [ -s "$SUBDOMAINS_FILE" ]; then
  while read -r SUB; do
    echo "$SUB" | jq -R '{host:.}' >> "$OUT"
  done < "$SUBDOMAINS_FILE"
fi
```

Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/subfinder/subfinder.jsonl`, one JSON record per subdomain discovered.

# dnsx – Resolving Hosts

[dnsx](https://github.com/projectdiscovery/dnsx) A fast and flexible DNS toolkit for running DNS queries. It can resolve hostnames, filter responses, and validate records, making it useful for verifying subdomain discoveries.  
**Use Cases:**

- Resolving subdomains found via Subfinder to check if they are alive.
- Performing DNS record lookups (A, CNAME, TXT, MX, etc.).
- Filtering valid domains from a large list.

```bash { name=dnsx }
OUT="$OPSFOLIO_EAA_HOME/dnsx/dnsx.jsonl"
mkdir -p "$(dirname "$OUT")"

jq -r 'select(.host!=null) | .host' $OPSFOLIO_EAA_HOME/subfinder/subfinder.jsonl \
  | sed 's/ .*//' \
  | grep -v -F -f "$OPSFOLIO_EAA_SESSION_HOME/excludes.txt" \
  | dnsx -json -silent -o "$OUT" || true
```

Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/dnsx/dnsx.jsonl` containing resolved IPs, CNAMEs, and other DNS data.

# httpx-toolkit – Probing Web Services

[httpx-toolkit](https://www.kali.org/tools/httpx-toolkit/) A fast HTTP toolkit that probes web servers to collect information such as status codes, titles, technologies, TLS details, redirects, and response headers. It helps identify live hosts and gather intelligence.  
**Use Cases:**

- Checking which discovered subdomains are live.
- Collecting metadata (status codes, titles, headers, TLS details).
- Identifying web technologies for further exploitation.

```bash { name=httpx }
OUT="$OPSFOLIO_EAA_HOME/httpx-toolkit/httpx-toolkit.jsonl"

# Create the output directory if it does not exist
mkdir -p "$(dirname "$OUT")"

jq -r .host $OPSFOLIO_EAA_HOME/dnsx/dnsx.jsonl \
  | grep -v -F -f "$OPSFOLIO_EAA_SESSION_HOME/excludes.txt" \
  > targets.txt || true

cat "$OPSFOLIO_EAA_SESSION_HOME/key_urls.txt" >> targets.txt || true

httpx-toolkit -l targets.txt -json -silent \
  -rl "${OPSFOLIO_EAA_RATE_LIMIT:-200}" \
  -threads "${OPSFOLIO_EAA_CONCURRENCY:-50}" \
  -o "$OUT"

```

Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/httpx/httpx-toolkit.jsonl` with fields like URL, status code, title, webserver header.

# WhatWeb – Fingerprinting Technologies

[WhatWeb](https://github.com/urbanadventurer/WhatWeb) A web scanner that identifies websites’ technologies, frameworks, CMS, server details, and other metadata. It’s useful for fingerprinting applications during reconnaissance.  
**Use Cases:**

- Detecting CMS (e.g., WordPress, Joomla, Drupal) in use.
- Identifying server-side technologies (Apache, Nginx, PHP, etc.).
- Profiling web applications for potential vulnerabilities.

```bash { name=whatweb }
mkdir -p $OPSFOLIO_EAA_HOME/whatweb

# Extract URLs, remove excluded ones, remove duplicates
jq -r .url $OPSFOLIO_EAA_HOME/httpx-toolkit/httpx-toolkit.jsonl \
  | grep -v -F -f "$OPSFOLIO_EAA_SESSION_HOME/excludes.txt" \
  | sort -u \
  | while read -r url; do
      safe=$(echo "$url" | sed 's#[/:?&=]#_#g')
      whatweb --log-json="$OPSFOLIO_EAA_HOME/whatweb/$safe.json" "$url" || true
    done

```

Artifacts: per-target JSON files under `$OPSFOLIO_EAA_HOME/whatweb/whatweb.jsonl` with detected technologies.
The way to detect anomalies using WhatWeb findings include:

- Refer [whatweb-security-engineer.ctxe.md](./whatweb-security-engineer.ctxe.md)

# Naabu – Scanning Open Ports

[Naabu](https://github.com/projectdiscovery/naabu) A fast port scanner written in Go. It can scan large IP ranges to identify open ports, serving as a lightweight and high-performance alternative to traditional scanners.  
**Use Cases:**

- Discovering open ports on a target system.
- Identifying exposed services (HTTP, SSH, FTP, etc.).
- Feeding live ports into service enumeration tools like Nmap.

```bash { name=naabu }
mkdir -p $OPSFOLIO_EAA_HOME/naabu

jq -r .host $OPSFOLIO_EAA_HOME/dnsx/dnsx.jsonl \
  | grep -v -F -f "$OPSFOLIO_EAA_SESSION_HOME/excludes.txt" \
  > naabu_hosts.txt || true

naabu -list naabu_hosts.txt -json -silent \
  -top-ports "${OPSFOLIO_EAA_NAABU_PORTS#top-}" \
  -rate "${OPSFOLIO_EAA_RATE_LIMIT:-200}" \
  -c "${OPSFOLIO_EAA_CONCURRENCY:-50}" \
  -o $OPSFOLIO_EAA_HOME/naabu/naabu.jsonl

```

Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/naabu/naabu.jsonl` with IP and port fields.

# Nmap – Service Enumeration

[Nmap](https://nmap.org/) One of the most popular and versatile network scanning tools. It detects open ports, services, versions, and even operating systems on target systems.  
**Use Cases:**

- Performing comprehensive port scanning and service detection.
- Detecting operating systems and service versions.
- Running vulnerability detection scripts (via NSE).

```bash { name=nmap }
# Ensure output directory exists
mkdir -p "$OPSFOLIO_EAA_HOME/nmap"

# Extract unique IPs from naabu.jsonl into a temporary file
TARGETS_FILE="$OPSFOLIO_EAA_HOME/nmap/nmap_targets.txt"
jq -r .ip "$OPSFOLIO_EAA_HOME/naabu/naabu.jsonl" | sort -u > "$TARGETS_FILE"

# Run nmap with aggressive scan (-A), no ping (-Pn), faster timing (-T4)
# Output in normal format (-oN)
nmap -A -Pn -T4 -oX "$OPSFOLIO_EAA_HOME/nmap/nmap.xml" -iL "$TARGETS_FILE" || true

# Remove the temporary targets file
rm -f "$TARGETS_FILE"
```

Artifacts: XML and JSON representations of Nmap results at `$OPSFOLIO_EAA_HOME/nmap/nmap.*`.

# OpenSSL – Inspecting TLS Certificates

[OpenSSL](https://www.openssl.org/) A robust toolkit for the Transport Layer Security (TLS) and Secure Sockets Layer (SSL) protocols. It’s used to generate and manage keys/certificates, test SSL connections, and troubleshoot cryptographic issues.  
**Use Cases:**

- Generating SSL/TLS certificates for secure communication.
- Testing SSL handshakes and debugging HTTPS issues.
- Checking for weak or expired certificates.

```bash { name=openssl }
# Ensure directory exists
mkdir -p $OPSFOLIO_EAA_HOME/openssl

for host in $(jq -r .host $OPSFOLIO_EAA_HOME/httpx-toolkit/httpx-toolkit.jsonl \
              | grep -v -F -f "$OPSFOLIO_EAA_SESSION_HOME/excludes.txt"); do
  safe=$(echo "$host" | sed 's#[/:]#_#g')   # sanitize filename
  echo | openssl s_client -servername "$host" -connect "$host:443" -showcerts 2>/dev/null \
        > "$OPSFOLIO_EAA_HOME/openssl/$safe.txt" || true
done
```

Artifacts: plain text certificate details in `$OPSFOLIO_EAA_HOME/openssl/*.txt`.

# Nuclei – Template-Based Vulnerability Scanning

[Nuclei](https://github.com/projectdiscovery/nuclei) A fast vulnerability scanner that uses community-contributed templates to detect misconfigurations, CVEs, exposures, and other security issues. It automates large-scale scanning with customizable templates.  
**Use Cases:**

- Scanning web apps for known CVEs using templates.
- Detecting misconfigurations (e.g., exposed panels, default creds).
- Automating bug bounty reconnaissance workflows.

```bash { name=nuclei }
# Ensure output directory exists
mkdir -p "$OPSFOLIO_EAA_HOME/nuclei"

# Extract only the hostnames from httpx results and save to temporary targets file
jq -r .url "$OPSFOLIO_EAA_HOME/httpx-toolkit/httpx-toolkit.jsonl" \
  | grep -v -F -f "$OPSFOLIO_EAA_SESSION_HOME/excludes.txt" \
  | sed -E 's,https?://([^/:]+).*,\1,' \
  | sort -u \
  > "$OPSFOLIO_EAA_HOME/nuclei/nuclei_targets.txt" || true

# Run nuclei against the extracted domains
nuclei -list "$OPSFOLIO_EAA_HOME/nuclei/nuclei_targets.txt" \
  -rate-limit "${OPSFOLIO_EAA_RATE_LIMIT:-200}" \
  -c "${OPSFOLIO_EAA_CONCURRENCY:-50}" \
  -o "$OPSFOLIO_EAA_HOME/nuclei/nuclei.txt" || true

# Remove temporary targets file
rm -f "$OPSFOLIO_EAA_HOME/nuclei/nuclei_targets.txt"
```

Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/nuclei/nuclei.jsonl` with one result per finding.

# Katana – Crawling for Endpoints

[Katana](https://github.com/projectdiscovery/katana) A powerful web crawling tool designed to discover hidden files, endpoints, and parameters. It supports modern web technologies (like JS parsing) and is useful for application mapping and content discovery.  
**Use Cases:**

- Crawling target websites to find hidden endpoints.
- Extracting URLs and parameters for fuzzing.
- Mapping web applications for deeper testing.

```bash { name=katana }
if command -v katana >/dev/null; then
  jq -r .url $OPSFOLIO_EAA_HOME/httpx-toolkit/httpx-toolkit.jsonl \
    | grep -v -F -f "$OPSFOLIO_EAA_SESSION_HOME/excludes.txt" \
    > katana_targets.txt || true

  # Ensure output directory exists
  mkdir -p $OPSFOLIO_EAA_HOME/katana

  katana -list katana_targets.txt -jsonl -o $OPSFOLIO_EAA_HOME/katana/katana.jsonl || true
fi
```

Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/katana/katana.jsonl` listing discovered endpoints.

# tlsx – TLS Metadata Extraction

[tlsx](https://github.com/projectdiscovery/tlsx) A TLS/SSL scanner that helps analyze SSL certificates, extract metadata, and check for security issues in TLS configurations. It is valuable for identifying weak or misconfigured SSL setups.  
**Use Cases:**

- Extracting SSL certificate details from multiple hosts.
- Identifying weak TLS versions or cipher suites.
- Monitoring certificate expiration across domains.

```bash { name=tlsx }
if command -v tlsx >/dev/null; then
  # Ensure output directory exists
  mkdir -p $OPSFOLIO_EAA_HOME/tlsx

  # Write targets inside the same folder
  jq -r .host $OPSFOLIO_EAA_HOME/httpx-toolkit/httpx-toolkit.jsonl \
    | grep -v -F -f "$OPSFOLIO_EAA_SESSION_HOME/excludes.txt" \
    > $OPSFOLIO_EAA_HOME/tlsx/tlsx_targets.txt || true

  # Only run if we have targets
  if [ -s $OPSFOLIO_EAA_HOME/tlsx/tlsx_targets.txt ]; then
    tlsx -list $OPSFOLIO_EAA_HOME/tlsx/tlsx_targets.txt \
         -silent  \
         -json -o $OPSFOLIO_EAA_HOME/tlsx/tlsx.jsonl || true
  else
    echo "[INFO] No TLSX targets found"
  fi
# Remove services.xml after conversion
rm -f $OPSFOLIO_EAA_HOME/tlsx/tlsx_targets.txt
fi
```

- Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/tlsx/tlsx.jsonl` with structured TLS details.

# Dirsearch – Directory Enumeration

[Dirsearch](https://github.com/projectdiscovery/tlsx) Dirsearch is an open-source command-line tool used for brute-forcing directories and files on web servers. It helps security testers and administrators discover hidden resources, misconfigured files, and sensitive endpoints that are not publicly linked. The tool supports multithreading, custom wordlists, recursive scans, proxy support, and can handle various HTTP methods, making it efficient for web application reconnaissance and vulnerability assessments.

Use Cases

- Hidden Path Discovery
- Exposure of Misconfigurations
- Recon in Pentesting

```bash { name=dirsearch }
if command -v dirsearch >/dev/null; then
  OUT="$OPSFOLIO_EAA_HOME/dirsearch/dirsearch.json"
  mkdir -p "$(dirname "$OUT")"

  # Create key_urls.txt from env variable
  KEY_URLS_FILE="$OPSFOLIO_EAA_SESSION_HOME/key_urls.txt"
  mkdir -p "$(dirname "$KEY_URLS_FILE")"
  echo "$OPSFOLIO_EAA_KEY_URLS" | tr ',' '\n' | tr ' ' '\n' > "$KEY_URLS_FILE"

  # Run dirsearch directly on key_urls.txt
  dirsearch -l "$KEY_URLS_FILE" -i 200 --format=json -o "$OUT" >/dev/null 2>&1 || true
fi
```

- Artifacts: JSONL file at `/$OPSFOLIO_EAA_HOME/dirsearch/dirsearch.jsonl` with structured TLS details.

# wafw00f – Fingerprints Web Application Firewall (WAF)

[wafw00f](https://www.kali.org/tools/wafw00f/) WAFW00F is a Web Application Firewall (WAF) fingerprinting tool. It helps security testers and penetration testers detect whether a website is protected by a WAF and, if so, identify the specific vendor or technology in use. It works by sending crafted HTTP requests and analyzing responses to determine patterns that match known WAF behaviors.

Use Cases

- Identify if a target application is protected by a WAF so that penetration testers can adjust their testing approach accordingly.
- Determine the specific WAF vendor (e.g., Cloudflare, Akamai, Imperva) to understand its protection mechanisms and known bypass techniques.
- Validate whether an organization has correctly deployed a WAF as part of regulatory compliance (e.g., PCI DSS) or general security hardening.

```bash { name=wafw00f }
IN="$OPSFOLIO_EAA_HOME/dnsx/dnsx.jsonl"
OUT="$OPSFOLIO_EAA_HOME/wafw00f/wafw00f.txt"

mkdir -p "$(dirname "$OUT")"

# Run wafw00f on resolved hosts with timeout
jq -r 'select(.host!=null) | .host' "$IN" \
  | sort -u \
  | while read -r host; do
      wafw00f -a --no-colors "$host" || true
    done > "$OUT" || true
```

- Artifacts: JSONL file at `/var/fleetfolio/eaa/wafw00f/wafw00f.jsonl` with structured TLS details.

# Testssl – SSL/TLS Security Testing Tool

[Testssl](https://github.com/testssl/testssl.sh) Testssl.sh is an open-source command-line tool used to test SSL/TLS configurations of servers.

Use Cases

- Detect weak or deprecated SSL/TLS protocols and ciphers.
- Identify SSL/TLS misconfigurations (e.g., insecure renegotiation, Heartbleed).

```bash { name=Testssl }
IN="$OPSFOLIO_EAA_SESSION_HOME/key_urls.txt"
OUT="$OPSFOLIO_EAA_HOME/testssl/testssl.json"

mkdir -p "$(dirname "$OUT")"

# Corrected syntax
testssl --file "$IN" --jsonfile-pretty "$OUT"
```

- Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/testssl/testssl.jsonl` with structured TLS details.

# Sqlmap – SSL/TLS Security Testing Tool

[Sqlmap](https://github.com/sqlmapproject/sqlmap) is an open-source penetration testing tool that automates the process of detecting and exploiting SQL injection vulnerabilities in web applications. It supports a wide range of databases and can help security testers identify and confirm database flaws quickly.

Use Cases

- Detect SQL Injection – Automatically test web applications for SQL injection vulnerabilities.
- Database Enumeration – Extract database names, tables, columns, and even data from vulnerable applications.
- Privilege Escalation & Access – Identify database users, check privileges, and attempt to gain administrative access to the backend.

```bash { name=Sqlmap }
IN="$OPSFOLIO_EAA_SESSION_HOME/key_urls.txt"
OUT="$OPSFOLIO_EAA_HOME/sqlmap/sqlmap.txt"

mkdir -p "$(dirname "$OUT")"

# Run sqlmap on each URL and append results to OUT
cat "$IN" | sort -u | while read -r url; do
    {
        echo "=================================================="
        echo "[*] Testing URL: $url"
        echo "=================================================="
        sqlmap --random-agent --batch \
               --current-user --current-db \
               -u "$url" || true
        echo
    } >> "$OUT"
done
```

- Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/sqlmap/sqlmap.jsonl` with structured TLS details.

# Subzy – Subdomain takeover

[Subzy](https://github.com/PentestPad/subzy) is an open-source tool used to detect and exploit subdomain takeover vulnerabilities. It scans for misconfigured subdomains pointing to deprovisioned services which works based on matching response fingerprints from [can-i-take-over-xyz](https://github.com/EdOverflow/can-i-take-over-xyz/blob/master/README.md).

Use Cases

- Identify subdomains vulnerable to takeover due to misconfigured DNS records.
- Automate reconnaissance during bug bounty or penetration testing.
- Prevent security risks by monitoring and fixing dangling subdomains in an organization.

```bash { name=Subzy }
IN="$OPSFOLIO_EAA_HOME/subfinder/subfinder.jsonl"
TXT_OUT="$OPSFOLIO_EAA_HOME/subzy/subzy-temp.txt"
OUT="$OPSFOLIO_EAA_HOME/subzy/subzy.txt"

# Ensure output directory exists
mkdir -p "$(dirname "$OUT")"

# Extract subdomains → save to TXT
jq -r '.host' "$IN" | sort -u > "$TXT_OUT"

# Run subzy → strip ANSI colors → save clean output
subzy run --targets "$TXT_OUT" \
  | sed -r "s/\x1B\[[0-9;]*[mK]//g" \
  > "$OUT"

# Remove TXT file after use
rm -f "$TXT_OUT"
```

# Convert Results into SQLite Database with Surveilr

After the scanning process, the collected results are normalized and stored in a single SQLite database file named resource-surveillance.sqlite.db. This step ensures that all findings are structured, queryable, and ready for further analysis or reporting through Surveilr.

```bash { name=surveilr }
IN="$OPSFOLIO_EAA_HOME"
OUT="$OPSFOLIO_EAA_HOME"

# Extract the timestamp from the session directory name
timestamp=$(basename "$OPSFOLIO_EAA_HOME")

surveilr ingest files -r . \
  --tenant-id "$OPSFOLIO_EAA_TENANT_ID" \
  --tenant-name "$OPSFOLIO_EAA_TENANT_NAME" \
  --state-db-fs-path "$OUT/$OPSFOLIO_EAA_TENANT_ID.$timestamp.opsfolio-eaa-rssd.sqlite.db"
```

Artifacts: Convert Results into SQLite Database with Surveilr.

# Analyst’s Guide to Interpreting Artifacts

This appendix provides practical advice for reviewing the artifacts generated by each tool. It is meant for analysts who may
not be familiar with the nuances of every tool but need to make sense of the outputs.

## Subfinder (`subfinder.jsonl`)

Each line is a JSON object with a `host` field and the `source` where it was discovered. Analysts should look for:

- Subdomains that are unexpected or unmanaged.
- Entries that do not resolve later in dnsx, which may indicate legacy or abandoned records.

## dnsx (`dnsx.jsonl`)

DNS resolution results will include IPs (A/AAAA records), CNAMEs, and other metadata. Analysts should:

- Verify that IPs map to owned infrastructure.
- Flag any pointing to cloud or third-party networks that might be unmanaged.

## httpx-toolkit (`httpx-toolkit.jsonl`)

Contains metadata for live web services: status codes, titles, server headers. Analysts should:

- Look for sensitive endpoints (e.g., admin panels, login portals).
- Pay attention to unusual server headers or technologies that don’t align with policy.

## WhatWeb (`whatweb/*.json`)

Per-target JSON files list detected plugins/technologies. Analysts should:

- Identify outdated CMS or frameworks (e.g., old WordPress, Joomla).
- Cross-check detected versions against known vulnerabilities.

## Naabu (`naabu.jsonl`)

JSON lines listing IPs and open ports. Analysts should:

- Spot unexpected open ports (e.g., databases, RDP, SSH exposed externally).
- Focus on high-risk services like SMB, Telnet, or legacy protocols.

## Nmap (`nmap.xml`)

Provides enriched service banners and versions. Analysts should:

- Confirm the accuracy of Naabu findings.
- Evaluate service versions for end-of-life software.

## OpenSSL (`tls/*.txt`)

Raw transcripts of TLS handshakes and certificate chains. Analysts should:

- Check expiry dates, SAN entries, and certificate issuers.
- Flag self-signed or weakly signed certificates.

## Nuclei (`nuclei.txt`)

Each JSON line represents a finding matched against a template. Analysts should:

- Sort by severity to prioritize triage.
- Validate important findings manually before reporting.

## Katana (`katana.jsonl`)

Lists discovered web endpoints through crawling. Analysts should:

- Look for API endpoints, hidden admin paths, or sensitive resources.
- Cross-reference endpoints against vulnerability scan coverage.

## tlsx (`tlsx.jsonl`)

Structured TLS metadata such as cipher suites and certificate details. Analysts should:

- Use this to complement OpenSSL outputs with machine-friendly JSON data.
- Review for weak ciphers or deprecated protocol versions.

## Dirsearch (`dirsearch.json`)

Structured drsearch metadata such as cipher suites and certificate details. Analysts should:

- Use this to complement OpenSSL outputs with machine-friendly JSON data.
- Review for weak ciphers or deprecated protocol versions.

## wafw00f (`wafw00f.txt`)

Structured drsearch metadata such as cipher suites and certificate details. Analysts should:

- Use this to complement OpenSSL outputs with machine-friendly JSON data.
- Review for weak ciphers or deprecated protocol versions.

## Testssl (`testssl.json`)

Structured drsearch metadata such as cipher suites and certificate details. Analysts should:

- Use this to complement OpenSSL outputs with machine-friendly JSON data.
- Review for weak ciphers or deprecated protocol versions.

## Sqlmap (`sqlmap.txt`)

Structured drsearch metadata such as cipher suites and certificate details. Analysts should:

- Use this to complement OpenSSL outputs with machine-friendly JSON data.
- Review for weak ciphers or deprecated protocol versions.

## subzy (`subzy.txt`)

Structured drsearch metadata such as cipher suites and certificate details. Analysts should:

- Use this to complement OpenSSL outputs with machine-friendly JSON data.
- Review for weak ciphers or deprecated protocol versions.
---

This guide should be used alongside the summary step to quickly assess which artifacts need deeper analysis.






